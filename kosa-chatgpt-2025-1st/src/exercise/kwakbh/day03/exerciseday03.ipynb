{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc.load_page(page_num)\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "# PDF 파일 경로\n",
    "pdf_path = \"/home/ubuntu/work/kosa-chatgpt-2025-1st/src/exercise/kwakbh/day03/소나기.pdf\"\n",
    "\n",
    "pdf_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "# 텍스트를 임베딩하고 저장.\n",
    "embeddings = OpenAIEmbeddings()  \n",
    "vector_db_path = \"/home/ubuntu/work/kosa-chatgpt-2025-1st/src/exercise/kwakbh/day03/sonagi/\"\n",
    "vector_db = FAISS.from_texts([pdf_text], embeddings)\n",
    "vector_db.save_local(vector_db_path)\n",
    "\n",
    "user_input = input(\"질문할 내용을 입력하세요: \")\n",
    "\n",
    "# 관련 문서를 검색합니다.\n",
    "docs = vector_db.similarity_search(user_input, k=5)  # 유사한 상위 5개의 문서를 검색\n",
    "\n",
    "documents_text = \"\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "다음은 PDF 문서에서 검색된 관련 내용입니다:\n",
    "{documents_text}\n",
    "\n",
    "이 정보를 기반으로 사용자의 질문에 답변해주세요: {user_input}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(input_variables=[\"documents_text\", \"user_input\"], template=prompt_template)\n",
    "\n",
    "# LLM 초기화\n",
    "chat = ChatOpenAI(model_name='gpt-4o-mini', temperature=0.9)\n",
    "qa_chain = load_qa_chain(chat, chain_type=\"stuff\")\n",
    "\n",
    "response = qa_chain.run(input_documents=docs, question=user_input)\n",
    "\n",
    "print(\"\\n답변:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#실습 #2: 만든 ChatGPT 어플리케이션을 gradio 인터페이스로 수정하시오. \n",
    "# 파일을 VectorDB로 변환하는 ingest.py와 해당 VectorDB를 사용하는 ask_pdf.py 두개 파일로 생성하시오. \n",
    "# 스트리밍을 사용하시오. (시간이 된다면) 파일 업로드 기능을 추가한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import gradio as gr\n",
    "import os\n",
    "\n",
    "# PDF에서 텍스트 추출 함수\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc.load_page(page_num)\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "# PDF 파일을 처리하고 질문에 답변하는 함수\n",
    "def answer_question(pdf_file, user_input):\n",
    "    pdf_text = extract_text_from_pdf(pdf_file.name)\n",
    "    \n",
    "    # 텍스트를 임베딩하고 벡터 DB에 저장\n",
    "    embeddings = OpenAIEmbeddings()  \n",
    "    vector_db_path = \"/tmp/vector_db\"  # 임시 디렉토리 사용\n",
    "    vector_db = FAISS.from_texts([pdf_text], embeddings)\n",
    "    vector_db.save_local(vector_db_path)\n",
    "\n",
    "    # 관련 문서를 검색\n",
    "    docs = vector_db.similarity_search(user_input, k=5)  # 유사한 상위 5개의 문서 검색\n",
    "\n",
    "    documents_text = \"\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "    prompt_template = \"\"\"\n",
    "    다음은 PDF 문서에서 검색된 관련 내용입니다:\n",
    "    {documents_text}\n",
    "\n",
    "    이 정보를 기반으로 사용자의 질문에 답변해주세요: {user_input}\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = PromptTemplate(input_variables=[\"documents_text\", \"user_input\"], template=prompt_template)\n",
    "\n",
    "    chat = ChatOpenAI(model_name='gpt-4o-mini', temperature=0.9)\n",
    "    qa_chain = load_qa_chain(chat, chain_type=\"stuff\")\n",
    "\n",
    "    response = qa_chain.run(input_documents=docs, question=user_input)\n",
    "    return response\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot()\n",
    "    msg = gr.Textbox(placeholder=\"질문을 입력하세요.\", label=\"질문\")\n",
    "    pdf_file = gr.File(label=\"PDF 파일 업로드\")\n",
    "    clear = gr.ClearButton([msg, chatbot])\n",
    "\n",
    "    def chat_function(history, pdf_file, user_input):\n",
    "        response = answer_question(pdf_file, user_input)\n",
    "        history.append((user_input, response))\n",
    "        return history\n",
    "\n",
    "    msg.submit(chat_function, [chatbot, pdf_file, msg], chatbot)\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting streamlit\n",
      "  Downloading streamlit-1.41.1-py2.py3-none-any.whl (9.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting cachetools<6,>=4.0\n",
      "  Downloading cachetools-5.5.1-py3-none-any.whl (9.5 kB)\n",
      "Collecting pyarrow>=7.0\n",
      "  Downloading pyarrow-19.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (42.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<3,>=1.23 in /home/ubuntu/.local/lib/python3.10/site-packages (from streamlit) (1.26.4)\n",
      "Collecting altair<6,>=4.0\n",
      "  Downloading altair-5.5.0-py3-none-any.whl (731 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.2/731.2 KB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tornado<7,>=6.0.3 in /home/ubuntu/.local/lib/python3.10/site-packages (from streamlit) (6.4.2)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /home/ubuntu/.local/lib/python3.10/site-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from streamlit) (13.9.4)\n",
      "Requirement already satisfied: packaging<25,>=20 in /home/ubuntu/.local/lib/python3.10/site-packages (from streamlit) (24.2)\n",
      "Collecting toml<2,>=0.10.1\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7\n",
      "  Downloading GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.6/207.6 KB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting protobuf<6,>=3.20\n",
      "  Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 KB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas<3,>=1.4.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from streamlit) (2.2.3)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from streamlit) (11.1.0)\n",
      "Collecting pydeck<1,>=0.8.0b4\n",
      "  Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click<9,>=7.0 in /usr/lib/python3/dist-packages (from streamlit) (8.0.3)\n",
      "Collecting watchdog<7,>=2.1.5\n",
      "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 KB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from streamlit) (8.5.0)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /usr/lib/python3/dist-packages (from altair<6,>=4.0->streamlit) (3.2.0)\n",
      "Collecting narwhals>=1.14.2\n",
      "  Downloading narwhals-1.23.0-py3-none-any.whl (306 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m306.2/306.2 KB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from altair<6,>=4.0->streamlit) (3.0.3)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 KB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ubuntu/.local/lib/python3.10/site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ubuntu/.local/lib/python3.10/site-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.27->streamlit) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ubuntu/.local/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.27->streamlit) (2020.6.20)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from rich<14,>=10.14.0->streamlit) (2.19.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.16.0)\n",
      "Installing collected packages: watchdog, toml, smmap, pydeck, pyarrow, protobuf, narwhals, cachetools, gitdb, altair, gitpython, streamlit\n",
      "Successfully installed altair-5.5.0 cachetools-5.5.1 gitdb-4.0.12 gitpython-3.1.44 narwhals-1.23.0 protobuf-5.29.3 pyarrow-19.0.0 pydeck-0.9.1 smmap-5.0.2 streamlit-1.41.1 toml-0.10.2 watchdog-6.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-22 15:16:32.202 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-22 15:16:32.275 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /home/ubuntu/.local/lib/python3.10/site-packages/ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-01-22 15:16:32.276 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-22 15:16:32.277 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-22 15:16:32.278 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-22 15:16:32.279 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-22 15:16:32.280 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-22 15:16:32.281 Session state does not function when running a script without `streamlit run`\n",
      "2025-01-22 15:16:32.283 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-22 15:16:32.284 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-22 15:16:32.285 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-22 15:16:32.286 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-22 15:16:32.287 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-22 15:16:32.288 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-22 15:16:32.289 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-22 15:16:32.292 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-22 15:16:32.294 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-22 15:16:32.295 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-22 15:16:32.297 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-22 15:16:32.299 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "import streamlit as st\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def chatgpt_respond(message, chat_history):\n",
    "    messages = [{\"role\": \"system\", \"content\": \"넌 불친절한 챗봇이야\"}]\n",
    "    for user_msg, bot_msg in chat_history:\n",
    "        messages.append(\n",
    "            {\"role\": \"user\", \"content\": user_msg}\n",
    "            )\n",
    "        if bot_msg is not None:\n",
    "            messages.append(\n",
    "                {\"role\": \"assistant\", \"content\": bot_msg}\n",
    "                )\n",
    "\n",
    "    messages.append({\"role\": \"user\", \"content\": message})\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\", \n",
    "        messages=messages,\n",
    "        stream=True\n",
    "        )\n",
    "    bot_message = \"\"\n",
    "\n",
    "    for gen in response:\n",
    "        delta = getattr(gen.choices[0].delta, 'content', None)\n",
    "        if delta:\n",
    "            bot_message += delta\n",
    "            yield message, chat_history + [(message, bot_message)]\n",
    "    \n",
    "    chat_history.append((message, bot_message))\n",
    "    yield \"\", chat_history\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "st.title(\"ChatGPT with Streamlit\")\n",
    "\n",
    "message = st.text_input(\"You:\", key=\"user_message\")\n",
    "\n",
    "if st.button(\"Send\"):\n",
    "    if message:\n",
    "        chat_response = st.empty()\n",
    "        for msg, hist in chatgpt_respond(message, chat_history):\n",
    "            chat_history = hist\n",
    "            chat_response.text_area(\"Chat History\", value=\"\\n\".join([f\"User: {m}\\nBot: {b}\" for m, b in chat_history]))\n",
    "        st.text_input(\"You:\", value=\"\", key=\"user_message\")\n",
    "    \n",
    "if st.button(\"Clear Chat\"):\n",
    "    chat_history = []\n",
    "    st.experimental_rerun()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
