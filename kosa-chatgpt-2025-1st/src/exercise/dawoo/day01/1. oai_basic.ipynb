{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now_path = os.path.dirname(__file__)  # .py ê¸°ì¤€\n",
    "now_path = os.getcwd()  # .ipynb ê¸°ì¤€\n",
    "dotenv_path = os.path.join(os.path.dirname(now_path), '.env')\n",
    "\n",
    "load_dotenv(dotenv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "model = \"gpt-3.5-turbo-instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ã“ã‚“ã«ã¡ã¯ï¼Ÿ ä»Šæ—¥ã®å¤©æ°—ãŒè‰¯ã„ã§ã™ã­ï¼\n"
     ]
    }
   ],
   "source": [
    "response = openai.completions.create(\n",
    "    model=model,\n",
    "    prompt= \"ë‹¤ìŒì„ ì¼ë³¸ì–´ë¡œ ë²ˆì—­ í•˜ì„¸ìš”: ì•ˆë…•í•˜ì„¸ìš”? ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì¢‹ë„¤ìš”!\",\n",
    "    max_tokens=256,\n",
    ")\n",
    "\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(id='cmpl-AsgZSJrLmlU0blz7E9Z9r1KlqBUcS', choices=[CompletionChoice(finish_reason='length', index=0, logprobs=None, text=' ë‹¨ë°±ì§ˆ ì„­ì·¨ëŸ‰ì„ ëŠ˜ë¦¬ì‹­ì‹œì˜¤.\\n\\n\\nì¼ë°˜ì ìœ¼ë¡œ ìš´ë™ì„ í•˜ë©´ ê·¼ìœ¡ì˜ ì„±ì¥ê³¼ íšŒë³µì„ ìœ„í•´ ë‹¨ë°±ì§ˆ ì„­ì·¨ëŸ‰ì„ ì¦ê°€ì‹œì¼œì•¼ í•©ë‹ˆë‹¤. ê·¼ìœ¡ì€ ë‹¨ë°±ì§ˆë¡œ êµ¬ì„±ë˜ì–´ìˆê¸° ë•Œë¬¸ì—, ë‹¨ë°±ì§ˆì€ ê·¼ìœ¡ì„ ì¦ê°€ì‹œí‚¤ê¸° ìœ„í•œ í•„ìˆ˜ ì˜ì–‘ì†Œì…ë‹ˆë‹¤.\\n\\nì¼ë°˜ì ìœ¼ë¡œ ë‹¨ë°±ì§ˆ ì„­ì·¨ëŸ‰ì˜ ì ì ˆí•œ ìˆ˜ì¤€ì€ ì²´ì¤‘ì˜ 1.2~1.7g/kgì…ë‹ˆë‹¤. í•˜ì§€ë§Œ ê·¼ìœ¡ì˜ í¬ê¸°ë¥¼ ëŠ˜ë¦¬ê¸° ìœ„í•´ì„œëŠ” ë” ë†’ì€ ìˆ˜ì¹˜ì¸ 1.7~2.2g/kgì˜ ë‹¨ë°±ì§ˆ ì„­ì·¨ëŸ‰ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\\në‹¨ë°±ì§ˆì€ ì ì ˆí•œ ìˆ˜ì¤€ì—ì„œ ì„­ì·¨í•˜ì§€')], created=1737596718, model='gpt-3.5-turbo-instruct', object='text_completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=256, prompt_tokens=11, total_tokens=267, completion_tokens_details=None, prompt_tokens_details=None))\n",
      "CompletionChoice(finish_reason='length', index=0, logprobs=None, text=' ë‹¨ë°±ì§ˆ ì„­ì·¨ëŸ‰ì„ ëŠ˜ë¦¬ì‹­ì‹œì˜¤.\\n\\n\\nì¼ë°˜ì ìœ¼ë¡œ ìš´ë™ì„ í•˜ë©´ ê·¼ìœ¡ì˜ ì„±ì¥ê³¼ íšŒë³µì„ ìœ„í•´ ë‹¨ë°±ì§ˆ ì„­ì·¨ëŸ‰ì„ ì¦ê°€ì‹œì¼œì•¼ í•©ë‹ˆë‹¤. ê·¼ìœ¡ì€ ë‹¨ë°±ì§ˆë¡œ êµ¬ì„±ë˜ì–´ìˆê¸° ë•Œë¬¸ì—, ë‹¨ë°±ì§ˆì€ ê·¼ìœ¡ì„ ì¦ê°€ì‹œí‚¤ê¸° ìœ„í•œ í•„ìˆ˜ ì˜ì–‘ì†Œì…ë‹ˆë‹¤.\\n\\nì¼ë°˜ì ìœ¼ë¡œ ë‹¨ë°±ì§ˆ ì„­ì·¨ëŸ‰ì˜ ì ì ˆí•œ ìˆ˜ì¤€ì€ ì²´ì¤‘ì˜ 1.2~1.7g/kgì…ë‹ˆë‹¤. í•˜ì§€ë§Œ ê·¼ìœ¡ì˜ í¬ê¸°ë¥¼ ëŠ˜ë¦¬ê¸° ìœ„í•´ì„œëŠ” ë” ë†’ì€ ìˆ˜ì¹˜ì¸ 1.7~2.2g/kgì˜ ë‹¨ë°±ì§ˆ ì„­ì·¨ëŸ‰ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\\në‹¨ë°±ì§ˆì€ ì ì ˆí•œ ìˆ˜ì¤€ì—ì„œ ì„­ì·¨í•˜ì§€')\n",
      " ë‹¨ë°±ì§ˆ ì„­ì·¨ëŸ‰ì„ ëŠ˜ë¦¬ì‹­ì‹œì˜¤.\n",
      "\n",
      "\n",
      "ì¼ë°˜ì ìœ¼ë¡œ ìš´ë™ì„ í•˜ë©´ ê·¼ìœ¡ì˜ ì„±ì¥ê³¼ íšŒë³µì„ ìœ„í•´ ë‹¨ë°±ì§ˆ ì„­ì·¨ëŸ‰ì„ ì¦ê°€ì‹œì¼œì•¼ í•©ë‹ˆë‹¤. ê·¼ìœ¡ì€ ë‹¨ë°±ì§ˆë¡œ êµ¬ì„±ë˜ì–´ìˆê¸° ë•Œë¬¸ì—, ë‹¨ë°±ì§ˆì€ ê·¼ìœ¡ì„ ì¦ê°€ì‹œí‚¤ê¸° ìœ„í•œ í•„ìˆ˜ ì˜ì–‘ì†Œì…ë‹ˆë‹¤.\n",
      "\n",
      "ì¼ë°˜ì ìœ¼ë¡œ ë‹¨ë°±ì§ˆ ì„­ì·¨ëŸ‰ì˜ ì ì ˆí•œ ìˆ˜ì¤€ì€ ì²´ì¤‘ì˜ 1.2~1.7g/kgì…ë‹ˆë‹¤. í•˜ì§€ë§Œ ê·¼ìœ¡ì˜ í¬ê¸°ë¥¼ ëŠ˜ë¦¬ê¸° ìœ„í•´ì„œëŠ” ë” ë†’ì€ ìˆ˜ì¹˜ì¸ 1.7~2.2g/kgì˜ ë‹¨ë°±ì§ˆ ì„­ì·¨ëŸ‰ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ë‹¨ë°±ì§ˆì€ ì ì ˆí•œ ìˆ˜ì¤€ì—ì„œ ì„­ì·¨í•˜ì§€\n"
     ]
    }
   ],
   "source": [
    "response = openai.completions.create(\n",
    "    model=model,\n",
    "    prompt=\"ê·¼ìœ¡ì´ ì»¤ì§€ë ¤ë©´\",\n",
    "    max_tokens=256\n",
    ")\n",
    "\n",
    "print(response)\n",
    "print(response.choices[0])\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ã“ã‚“ã«ã¡ã¯ï¼Ÿä»Šæ—¥ã¯å¤©æ°—ãŒè‰¯ã„ã§ã™ã­ï¼\n"
     ]
    }
   ],
   "source": [
    "# í‘œì¤€ì ì¸ Chat completion mode\n",
    "model = 'gpt-3.5-turbo'\n",
    "\n",
    "res = openai.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[{\"role\":\"user\", \"content\":\"ë‹¤ìŒì„ ì¼ë³¸ì–´ë¡œ ë²ˆì—­ í•˜ì„¸ìš”: ì•ˆë…•í•˜ì„¸ìš”? ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì¢‹ë„¤ìš”!\"}]\n",
    ")\n",
    "\n",
    "print(res.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-Asgz2RfR1LzLPrlX3NTr4O6IGqZ2q', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='ã“ã‚“ã«ã¡ã¯ï¼Ÿä»Šæ—¥ã¯å¤©æ°—ãŒè‰¯ã„ã§ã™ã­ï¼', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1737598304, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=16, prompt_tokens=41, total_tokens=57, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¸”ë™í™€ì€ ì•„ì£¼ íŠ¹ë³„í•œ ê³³ìœ¼ë¡œ, ì‹œê°„ì´ ì§€ë‚˜ë©´ ì‚¬ë¼ì§ˆ ìˆ˜ ìˆì–´ìš”. ë¸”ë™í™€ì€ 'í˜¸í‚¹ ë³µì‚¬'ë¼ëŠ” ê²ƒìœ¼ë¡œ ì•„ì£¼ ì‘ì€ ì…ìë¥¼ ë‚´ë³´ë‚´ë©´ì„œ ì ì  ì‘ì•„ì ¸ìš”. ê·¸ëŸ¬ë©´ì„œ ì ì  ë°ì•„ì§€ë‹¤ê°€ ë§ˆì§€ë§‰ì—ëŠ” ì•„ì£¼ ê°•í•œ ë¹›ì„ ë‚´ê³  ì‚¬ë¼ì§„ë‹µë‹ˆë‹¤. í•˜ì§€ë§Œ ì´ ì¼ì´ ì¼ì–´ë‚˜ë ¤ë©´ ì •ë§ ì˜¤ëœ ì‹œê°„ì´ ê±¸ë ¤ìš”. íƒœì–‘ì²˜ëŸ¼ í° ë¸”ë™í™€ì´ ì‚¬ë¼ì§€ë ¤ë©´ 34ê²½ ë…„ì´ë¼ëŠ” ì•„ì£¼ ê¸´ ì‹œê°„ì´ í•„ìš”í•´ìš”! ê·¸ë˜ì„œ ë¸”ë™í™€ì´ ì‚¬ë¼ì§€ëŠ” ê±¸ ìš°ë¦¬ê°€ ë³´ê¸° í˜ë“  ì´ìœ ì˜ˆìš”. ì§€ê¸ˆê¹Œì§€ ë¸”ë™í™€ì´ ì‚¬ë¼ì§€ëŠ” ê±¸ ë³¸ ì ì€ ì—†ì–´ìš”.\n"
     ]
    }
   ],
   "source": [
    "response = openai.chat.completions.create(\n",
    "  model='gpt-4o-mini',\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"ì£¼ì–´ì§„ ë‚´ìš©ì„ ìœ ì¹˜ì›ìƒì—ê²Œ ì„¤ëª…í•  ìˆ˜ ìˆë„ë¡ ìš”ì•½í•˜ì‹œì˜¤.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"\"\"\n",
    "    ë¸”ë™í™€ë„ ìˆ˜ëª…ì´ ìˆìœ¼ë©°, í˜¸í‚¹ ë³µì‚¬ë¡œ ì…ìë¥¼ ë°©ì¶œí•˜ë‹¤ ì§ˆëŸ‰ì´ ì¤„ì–´ë“¤ì–´ ê²°êµ­ì—” ì‚¬ë¼ì§ˆ ê²ƒìœ¼ë¡œ ì˜ˆì¸¡ëœë‹¤. \n",
    "    ì§ˆëŸ‰ì„ ìƒìœ¼ë©´ì„œ ë¸”ë™í™€ì€ ì¡°ê¸ˆì”© ë°ì•„ì§€ë©°, ê±°ì˜ ë§ˆì§€ë§‰ì—” ì¦ë°œì´ ì‹¬í•´ì ¸ì„œ ì°½ë°±í•˜ê²Œ ë¹›ë‚˜ë©° ê³ ì—ë„ˆì§€ ê°ë§ˆì„ ê³¼ ì†Œë¦½ìë¥¼ ë°©ì¶œí•œë‹¤. \n",
    "    ë§ˆì§€ë§‰ì—ëŠ” ê°ë§ˆì„  í­ë°œì´ë¼ê³  í•´ë„ ë  ì •ë„ë¡œ ê²©ë ¬í•˜ê²Œ ê°ë§ˆì„ ì„ ë°©ì¶œí•˜ë©´ì„œ ì¦ë°œí•˜ê³  ì†Œë©¸í•œë‹¤. \n",
    "    ë‹¤ë§Œ ì¼ë°˜ì ìœ¼ë¡œ ì•Œë ¤ì ¸ ìˆëŠ” ë¸”ë™í™€ë“¤ì´ ì´ í­ë°œê¹Œì§€ ë„ë‹¬í•˜ë ¤ë©´ ë§¤ìš° ì˜¤ëœ ì‹œê°„ì´ ê±¸ë¦¬ë©°, \n",
    "    ì§ˆëŸ‰ì´ íƒœì–‘ ì •ë„ì¸ ë¸”ë™í™€ì´ ì¦ë°œí•´ì„œ ì†Œë©¸í•  ë•Œê¹Œì§€ëŠ” ì•½ 3.4Ã—1067ë…„ ì •ë„ê°€ ê±¸ë¦´ ê²ƒìœ¼ë¡œ ì¶”ì •ëœë‹¤. \n",
    "    ê·¸ë¦¬ê³  ë¸”ë™í™€ì˜ ìˆ˜ëª…ì€ ì§ˆëŸ‰ì— ë¹„ë¡€í•˜ë©°, í˜„ì¬ê¹Œì§€ ë°œê²¬ëœ ë¸”ë™í™€ë“¤ì€ ëª¨ë‘ íƒœì–‘ ì§ˆëŸ‰ ì´ìƒì´ë¯€ë¡œ ì¦ë°œí•˜ëŠ” ë°ì—ëŠ” ê·¸ë³´ë‹¤ ë” ì˜¤ëœ ì‹œê°„ì´ ê±¸ë¦°ë‹¤. \n",
    "    ë˜í•œ ë¸”ë™í™€ì˜ ì†Œë©¸ë¡œ ì¸í•´ ë°œìƒí•˜ëŠ” ê°ë§ˆì„  í­ë°œì˜ ê·œëª¨ëŠ” ê·¸ë¦¬ í¬ì§€ ì•Šì•„ íƒœì–‘ê³„ ì£¼ë³€ì—ì„œ ë°œìƒí•œ ê²½ìš°ê°€ ì•„ë‹ˆë©´ ë°œê²¬í•˜ê¸°ê°€ ì–´ë ¤ìš¸ ê²ƒìœ¼ë¡œ ì¶”ì •ë˜ë©° \n",
    "    í˜„ì¬ê¹Œì§€ ê´€ì¸¡ëœ ì‚¬ë¡€ê°€ ì—†ë‹¤.\"\"\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.5,\n",
    "  max_tokens=1024,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â˜€ï¸ğŸŒ¤ï¸ğŸŒ§ï¸ğŸŒˆ\n"
     ]
    }
   ],
   "source": [
    "response = openai.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ë¥¼ ì´ëª¨ì§€ë¡œ ë³€í™˜í•˜ì„¸ìš”. ì¼ë°˜ í…ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•˜ë©´ ì•ˆë˜ë©°, ì´ëª¨ì§€ë§Œ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"ì˜¤ëŠ˜ ë‚ ì”¨ëŠ” ë§‘ì•˜ë‹¤ê°€ ë¹„ê°€ ì™”ë‹¤ê°€ ì°¸ ë³€í™”ë¬´ìŒí•˜ë„¤ìš”.\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.8,\n",
    "  max_tokens=256,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
