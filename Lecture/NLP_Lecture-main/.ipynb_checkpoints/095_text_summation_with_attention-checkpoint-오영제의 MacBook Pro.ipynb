{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m83eOe_dzHP_"
   },
   "source": [
    "# 095. Text Summation using Attention Model\n",
    "\n",
    "- 전체 sentence 를 짧은 문장으로 요약  \n",
    "\n",
    "- NLP 의 Text Summarization approach 2 가지  \n",
    "    1. Extractive Summarization (추출 요약) - 원문에서 중요 문장/단어 추출  --> 전통적 approach\n",
    "    2. Abstractive Summarization (추상 요약) - 원문으로부터 새로운 문장 생성 --> Deep Learning approach  \n",
    "    \n",
    "- Encoder-Decode with Attention model 을 이용하여 긴 문장을 짧게 요약 \n",
    "\n",
    "## 실습 파일\n",
    "\n",
    "https://drive.google.com/drive/folders/1_6PfaUuPr04xJIV3Jqf6nxzYzF51WsUM\n",
    "\n",
    "- google drive \"내드라이브에 추가\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ibDo0B3izHQC"
   },
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import re  \n",
    "import time\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "colab_type": "code",
    "id": "j8NVu8WZ2T4o",
    "outputId": "cc4d77ab-ed0b-4a1b-ff41-6a83dba2b6b5"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tZXw6bujzHQH"
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"/content/drive/My Drive/amazon-fine-food-reviews/Reviews.csv\",nrows=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "colab_type": "code",
    "id": "9zuG9aF5zHQK",
    "outputId": "6a46e42c-9f61-4ff1-e418-a3ed56030d29"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Summary                                               Text\n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...\n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...\n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...\n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...\n",
       "4            Great taffy  Great taffy at a great price.  There was a wid..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['Summary', 'Text']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RG0MtqXfdYY6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"mini-amazon-food-review.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Summary                                               Text\n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...\n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...\n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...\n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...\n",
       "4            Great taffy  Great taffy at a great price.  There was a wid..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"mini-amazon-food-review.csv\")\n",
    "data[['Summary', 'Text']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 11)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ddWrGAIvzHQP"
   },
   "source": [
    "## drop duplicate and na values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k4Zx88TDzHQQ"
   },
   "outputs": [],
   "source": [
    "data.drop_duplicates(subset=['Text'], inplace=True)  #dropping duplicates\n",
    "data.dropna(axis=0, inplace=True)   #dropping na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_DsUg2WYzHQT"
   },
   "outputs": [],
   "source": [
    "def preprocess_sentence(sent):\n",
    "    cleaned_sentence = []\n",
    "    for txt in sent:\n",
    "        new_txt = re.sub(r'[^a-zA-Z ]', '', txt)\n",
    "        new_txt = new_txt.lower()\n",
    "        new_txt = new_txt.rstrip().strip()\n",
    "        cleaned_sentence.append('<start> ' + new_txt + ' <end>')\n",
    "    return cleaned_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ophUOtSYzHQY"
   },
   "outputs": [],
   "source": [
    "cleaned_text = preprocess_sentence(data['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "colab_type": "code",
    "id": "UUp0n91UIU_-",
    "outputId": "ed39926c-1abf-4436-d1d6-62fb7080c42b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start> i have bought several of the vitality canned dog food products and have found them all to be of good quality the product looks more like a stew than a processed meat and it smells better my labrador is finicky and she appreciates this product better than  most <end>',\n",
       " '<start> product arrived labeled as jumbo salted peanutsthe peanuts were actually small sized unsalted not sure if this was an error or if the vendor intended to represent the product as jumbo <end>',\n",
       " '<start> this is a confection that has been around a few centuries  it is a light pillowy citrus gelatin with nuts  in this case filberts and it is cut into tiny squares and then liberally coated with powdered sugar  and it is a tiny mouthful of heaven  not too chewy and very flavorful  i highly recommend this yummy treat  if you are familiar with the story of cs lewis the lion the witch and the wardrobe  this is the treat that seduces edmund into selling out his brother and sisters to the witch <end>',\n",
       " '<start> if you are looking for the secret ingredient in robitussin i believe i have found it  i got this in addition to the root beer extract i ordered which was good and made some cherry soda  the flavor is very medicinal <end>',\n",
       " '<start> great taffy at a great price  there was a wide assortment of yummy taffy  delivery was very quick  if your a taffy lover this is a deal <end>']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uaMrLpgpzHQd"
   },
   "outputs": [],
   "source": [
    "cleaned_summary = preprocess_sentence(data['Summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "id": "FPJQVJ35zHQh",
    "outputId": "9c06c89e-d6da-4e55-8905-067bc016bdc8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start> good quality dog food <end>',\n",
       " '<start> not as advertised <end>',\n",
       " '<start> delight says it all <end>',\n",
       " '<start> cough medicine <end>',\n",
       " '<start> great taffy <end>']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_summary[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "jx9hBYn6zHQl",
    "outputId": "a08b4efc-1847-4b55-c07c-5e1983eb6999"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9513\n",
      "9513\n"
     ]
    }
   ],
   "source": [
    "print(len(cleaned_text))\n",
    "print(len(cleaned_summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "colab_type": "code",
    "id": "5BygkHBAzHQp",
    "outputId": "af75b9d0-f204-4010-8f21-75dd62dbdb0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned_text 의 최대 길이 : 8782\n",
      "cleaned_text 의 최소 길이 : 62\n",
      "cleaned_text 의 평균 길이 : 414.06\n",
      "cleaned_summary 의 최대 길이 : 139\n",
      "cleaned_summary 의 최소 길이 : 14\n",
      "cleaned_summary 의 평균 길이 : 36.26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Summary')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfsAAADgCAYAAAAE7c8+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3de7zUVb3/8dcbEESF1ERDLoFGltrxhkRHS0oz1BLiaEdPKZYnyig1OaV4OWpqBztpmaWFCah5CRUNb4Wal58eRQFRNLwhqCgBZQJeAoHP74/vGhk2s2fPvsxlz34/H4957O+s+V4+e/b+zprv+q61PooIzMzMrH51qnYAZmZmVl6u7M3MzOqcK3szM7M658rezMyszrmyNzMzq3Ou7M3MzOqcK3szM7M658reWkTSW3mP9ZLezXv+1Vbsd3NJIalvW8ZrVu8k7S/p/yStkPSGpIcl7VvtuKw2dKl2ANY+RcRWuWVJi4D/jIh7qheRWcclqSdwO3ACMBXoCnwaWF3NuJpDkgBFxPpqx1KPfGVvZSGps6SzJL0k6W+SrpW0dXpttKTnJW2Znn9Z0mJJ2wAPpl08l1oJRlbrdzBrRz4KEBHXR8S6iHg3ImZExFOSzpH0u9yKkgak1rMu6fn9ks5PrQJvSbpN0gfTObtS0uOSBuRtH5K+I+kFSasknSdpZ0mPpPWnSuqa1t1G0u2Slkv6R1rum7ev+yVdIOlh4B1gnKTZ+b+YpHGSbi3nm9cRuLK3cvkBcDCwP9AXeA/4GUBEXAXMAy6StAPwa+DrEfEP4DNp+10iYquI8Elu1rTngXWSrpJ0SPri3BxHAccAfYCdgUeAycC2wHzg7AbrDwf2AYYCPwQmAl8F+gG7A0en9Tql/XwY6A+8C/yywb6OAcYAPYBfAAMlfTzv9a8B1zTz97EGXNlbuXwLOC0iXo+IfwLnAv+emuogO7kPB+4FboiIu6sUp1m7FxEryb5YB3AFsFzS9PRluhSTI2JBRKwA7gIWRMQ9EbEWuBHYq8H6F0bEyoh4BngamBERL+Vtv1eK6+8RcXNEvBMRq4ALgAMa7GtKRDwTEWsjYjXwe7IKHkm7AQPIblFYK7iytzaXKvR+wJ2S3pT0JvAE2f/bByH7EABuAXYFLq5WrGb1IiLmR8RxEdGX7Op6R+DnJW6+NG/53QLPt9p49dLWl7SFpN9IelnSSrLbdFtL6py3/qsN9n0V8B/pc+QYYGr6EmCt4Mre2lxkqRRfAz4XEVvnPTaPiL8BSBpC1tR3I1nT3fubVz5is/oSEc8CU8gq/beBLfJe/lAFQxkH7AJ8MiJ6suE2nfLW2eicj4hHgTVkHQz/AzfhtwlX9lYuvwYmSOoHIGl7SV9Ky1uQncDjgOOAXSR9AyB9g18B7FSNoM3aI0kfSx3Z+qbn/ci+TD8KzAU+I6m/pA8A4ysYWg+yK/03JW3Lpvf+G3M12b39tRHxULmC60hc2Vu5/AS4B/izpFXA/wF7p9cuAuZHxOSIeJesqe6neT1+/xu4Md0COLyyYZu1S6uATwIzJb1NVsk/DYxL/WF+DzwFzKay979/DnQH/pZi+mOJ211D1irhq/o2oqzF1czMrDZI6g4sA/aOiBeqHU898JW9mZnVmhOAx13Rtx3PoGdmZjUjzcgpwBNqtSE345uZmdU5N+ObmZnVOVf2ZmZmda5u79lvt912MWDAgGqHYVbzZs+e/beI6FXtOBrjc9msNMXO5bqt7AcMGMCsWbOqHYZZzZP0crVjKMbnsllpip3LbsY3MzOrc67szczM6pwrezMzszrnyt7MzKzOubI3MzOrc2XrjS9pc+BBoFs6zk0Rcbakc4BvAsvTqqdHxJ1pm/HA8cA64MSI+FMq34csN3N34E7gpGiDqf8GnHbHRs8XTTistbs0szqT/znhzwhrr8o59G418LmIeEvSZsBDku5Kr/0sIn6av7KkXYGjgN2AHYF7JH00ItYBlwNjyFIk3gkMB+7CzMzMmlS2ZvzIvJWebpYexa7GRwA3RMTqiFgIvAgMkdQb6BkRj6Sr+atxggQzM7OSlfWevaTOkuaS5SW+OyJmppe+K+kpSZMkbZPK+gCv5m2+OJX1ScsNy83MzKwEZa3sI2JdROwJ9CW7St+drEl+Z2BPYAlwUVpdhXZRpHwTksZImiVp1vLlywutYmYtkL6YL5P0dF7ZtpLulvRC+rlN3mvjJb0o6TlJX8gr30fSvPTaLyQVOr/NrI1VpDd+RLwJ3A8Mj4il6UvAeuAKYEhabTHQL2+zvsDrqbxvgfJCx5kYEYMjYnCvXjU71bdZezSFrK9MvtOAeyNiEHBvet6w/81w4DJJndM2uf43g9Kj4T7NrAzK2Ru/F/BeRLwpqTtwEHChpN4RsSSt9mUgd6UwHbhO0sVkHfQGAY9FxDpJqyQNBWYCxwKXlituM9tURDwoaUCD4hHAsLR8FdkX+lPJ638DLJSU63+ziNT/BkBSrv9NVTvbelSOdQTl7I3fG7gqfaPvBEyNiNslXSNpT7Km+EXAtwAi4hlJU4G/AGuBsaknPsAJbBh6dxfuiW9WC3bIfXGPiCWStk/lfchGzuTk+tm8h/vfmFVF2Sr7iHgK2KtA+TFFtrkAuKBA+Sxg9zYN0MzKpU3635A199O/f/+2i8ysg/IMembWUkvT0FjSz2Wp3P1vzGqMK3sza6npwOi0PBr4Q175UZK6SRrIhv43S4BVkoamXvjH5m1jZmVUznv2ZlYnJF1P1hlvO0mLgbOBCcBUSccDrwBHgvvfmNUiV/Zm1qSIOLqRlw5sZH33vzGrIW7GNzMzq3Ou7M3MzOqcK3szM7M658rezMyszrmyNzMzq3Ou7M3MzOqcK3szM7M658rezMyszrmyNzMzq3Nlq+wlbS7pMUlPSnpG0rmpfFtJd0t6If3cJm+b8ZJelPScpC/kle8jaV567RdpXm0zMzMrQTmv7FcDn4uIPYA9geGShgKnAfdGxCDg3vQcSbsCRwG7AcOByyR1Tvu6nCzd5aD0GF7GuM3MzOpK2Sr7yLyVnm6WHgGMAK5K5VcBI9PyCOCGiFgdEQuBF4EhKXVmz4h4JCICuDpvGzMzM2tCWe/ZS+osaS5Znuu7I2ImsENKdUn6uX1avQ/wat7mi1NZn7TcsLzQ8cZImiVp1vLly9v2lzEzM2unylrZR8S6iNgT6Et2lV4s21Wh+/BRpLzQ8SZGxOCIGNyrV6/mB2xmZlaHKtIbPyLeBO4nu9e+NDXNk34uS6stBvrlbdYXeD2V9y1QbmZmZiUoZ2/8XpK2TsvdgYOAZ4HpwOi02mjgD2l5OnCUpG6SBpJ1xHssNfWvkjQ09cI/Nm8bMzMza0KXMu67N3BV6lHfCZgaEbdLegSYKul44BXgSICIeEbSVOAvwFpgbESsS/s6AZgCdAfuSg8zMzMrQdkq+4h4CtirQPnfgQMb2eYC4IIC5bOAYvf7zcwqbsBpd2z0fNGEw6oUiVlxnkHPzMyszrmyNzMzq3Ou7M3MzOpck5W9pAGSuqbl/SV9R1LP8odmZm1t0aJFrFmzBoCHHnqIyy67DFr5pV/S91P+i6clXZ/yYjQ7B4aZlU8pJ/mtQEjamWyq2o8D15U1KjMri5EjRyKJBQsWcOyxxzJ//nyAnVq6P0l9gBOBwRGxO9CZLMdFS3JgmFmZlFLZr4+I94BRwM8j4ns0Ml2tmdW2Tp06sdlmmzFt2jROPvlkLr30UoCurdxtF6C7pC7AFmSTXjUrB0Yrj29mTShl6N1aSUcCx7DhhN2sfCFVT/4wGg+hsXrUpUsXbrzxRq655hpuvfXWXHGLU0ZHxGuSfko2Z8a7wIyImCFpoxwYkvJzYDyat4uCuS4kjSHLdEn//v1bGp6ZJaVc2X8D+Czwk4h4Kc1ud315wzKzcpg0aRL33XcfP/zhD9lpp51YuHAhwN9bur90L34EMBDYEdhS0teKbVKgbJNcF85zYda2SrmyHxYR38k9iYiFklaUMSYzK5P7778/1ykPgIEDBwKsa3SDph0ELIyI5QCSpgH/SsqBka7qS8mBYWZlVOqVfUPHt3UgZlZ+kyZNKlTcmkvnV4ChkrZIuSsOBObTzBwYrTi+mZWg0St7Sf9O1mt2YPq2ntMDeLPcgZlZ2/n973/PDTfcwMKFCxk1atT75atWrYIsF0WLRMRMSTcBc9J+ngAmAlvR/BwYZlYmxZrxHyO7l9cX+FVe+SqyE9rM2okhQ4bwwQ9+kMWLFzN27Nj3y3v06ME999zzQmv2HRFnA2c3KF5NM3NgmFn5NFrZp2ExCyW9GhHP5b8m6dPA/yt3cGbWNgYOHMjAgQPp168fu+yyS8OXt6xGTGZWOaXcs58m6RSAdJ/tZ8BPm9pIUj9J90man2bXOimVnyPpNUlz0+PQvG0KzqwlaR9J89Jrv0j3Bs2smUaNGsXFF18MwOrVq/n+978PWeudmdWxUir7TwIflfQQ8DjwBllv26asBcZFxMeBocDYNHsWwM8iYs/0uBOanFnrcrIxt4PSY3hJv52ZbWTmzJk8//zz7L///uy7775su+22AM9WOy4zK69SKvt/Av8APkDW3De/lA41EbEkIuak5VVkPXSLzbxXcGatNGynZ0Q8EhFBNmXvyCL7MbNGbL755myzzTasWLGCt99+m49//OPVDsnMKqCUyv5xskkv9gE+Axwn6YbmHETSAGAvYGYq+q6kpyRNykuQ0Qd4NW+z3MxafdJyw/JCxxkjaZakWcuXL29OiGYdwr777oskZs+ezYMPPsiUKVOgFXPjm1n7UEplf0JEnB4RayLitYj4IvCnUg8gaSvgZuDkiFhJ1iS/M7AnsAS4KLdqgc2jSPmmhZ51y6yoyy+/nB//+Md07dqVPn36cPvttwN4kiyzOtdkZR8Rj0oaKulYAEnbkmWxapKkzcgq+msjYlra39KIWBcR64Er2JAEo7GZtRazcQciz7hl1kJDhw7l0Ucf5eqrrwbgjTfegGw4rZnVsSany5V0JrAf2dX41UB3shS3+zexnYArye7xX5xX3juXIAP4MvB0Wp4OXCfpYrI5tgcBj0XEOkmrJA0luw1wLHBp6b+imeWcf/75PPzww++nuH333Xchm9fe2lh+Yi1wci2rrlLmxj+C7H57rrPda5J6lrDdfmSZ8uZJmpvKTgeOlrQnWVP8IuBbab/FZtY6AZhC9kXjrvQws2a66aabeOKJJ9h7770B6NOnD2Q56C1pWEmb1YNSKvvVERGSAkDSFqXsOCIeovD99juLbFNwZq2ImAXsXspxzaxx3bp1QxK5qSreeeedKkdkZpVQ6qQ6vwI+IOnrwAygYDYNM6tto0aNYuzYsaxYsYLJkydz8MEHA/yt2nGZWXk1eWUfERdKOgRYA+wBXBARbkY3a4dOPfVU7rrrLrp27cqTTz7JGWecwaGHHrqs6S3NrD0rlvVuRkQcDJAqd1fwZu3UwQcfzIwZMwA45JBDOOSQQ6ockZlVUrErew9UN6sTnmSqbbjznrVXxSr7D0ga1diLuXHzZlb7VqxYwbRpjZ6yW1cyFjOrvKKVPfBFGp/BzpW9WTuxYsUKbr/9drL0EptwZW9W54pV9i9HxDcqFomZlc2HP/xhJk0qPIhmypQpiyobjZlVWrGhd84Zb1YnGrmiN7MOolhlf0zFojCzsrrmmmuqHYKZVVGjlX1EPN3Ya2bWvuy+uyegNOvISpku18ysbnj4nHVEjV7ZS7o3/bywcuGYWTkceOCBQDaDXluTtLWkmyQ9K2m+pE9J2lbS3ZJeSD+3yVt/vKQXJT0n6QttHpCZbaLYPfvekg4ADpe0l6S98x9N7VhSP0n3pZP/GUknpfJmfwhI2kfSvPTaL5TL4mFmJVmyZAkPPPAA06dP54knnmDOnDnvP4CSklsVcQnwx4j4GNmU2vOB04B7I2IQcG96jqRdgaOA3YDhwGWSnHXPrMyKNeP/N9kJ2he4uMFrAXyuiX2vBcZFxBxJPYDZku4GjiP7EJgg6bR0jFMbfAjsCNwj6aMpze3lwBjgUbKsecPx9L1mJfvRj37EhAkTWLx4MaecckrDl/u2dL8p3fVnyM5rImINsEbSCGBYWu0q4H7gVGAEcENErAYWSnoRGAI80tIYzKxpjVb2EXETcJOksyLivObuOCKWAEvS8ipJ84E+ZCf7sLRakx8CkhYBPSPiEQBJVwMjcWVvVrIjjjiCI444gvPOO4+zzjpro9ckPd+KXe8ELAcmS9oDmA2cBOyQPgOIiCWStk/r9yH70p6zOJU1jGkM2Rd8+vfv34rwzAxKy3p3nqTDyb69A9wfEbc35yCSBgB7ATNp/ofAe2m5YbmZNdNZZ53F9OnTefDBBwEYNmxYa3fZBdgb+F5EzJR0CanJvhGNzci5cUHERGAiwODBgz1JgFkrNVnZS/ofsma2a1PRSZL2i4jxpRxA0lbAzcDJEbGyyO32xj4ESvpwSMfy1YBZEePHj+exxx7jq1/9KgCXXHIJtO7L82JgcUTMTM9vIqvsl0rqnb7Q9waW5a3fL2/7vsDrrTi+mZWglKF3hwF7RsR6AElXAU8ATVb2kjYjq+ivzUuc09wPgcVsfE+x0Q8HXw2YFXfHHXcwd+5cOnXK+uaOHj2aLl26fKCl+4uIv0p6VdIuEfEccCDwl/QYDUxIP/+QNpkOXCfpYrK+OYOAx1r8C5lZSYr1xs+XnyijpA+G1GP+SmB+ROR38JtOdvLDph8CR0nqJmkg6UMgNfmvkjQ07fPYvG3MrJnefPPN95dXrFjRFrv8HnCtpKeAPYEfk1Xyn5f0AvD59JyIeAaYSvZl4I/A2NQJ18zKqJQr+/8BnpB0H1mT+mco4aoe2I9syt15kuamstPJTvqpko4HXgGOhOxDQFLuQ2AtG38InABMAbqTdcxz5zyzFhg/fjx77bUXn/3sZ4mI3L37Ja3ZZ0TMBQYXeOnARta/ALigNcc0s+YppYPe9ZLuB/Ylq+xPjYi/lrDdQzSeTKdZHwIRMQvwfJ9mrXT00UczbNgwHn/8cSKCCy+8kN69e/+j2nGZWXmVNF1uakqfXuZYzKwCevfuzeGHH17tMMysgkq9Z29mZmbtlBPhmFndq1TyGyfZsVpV9MpeUidJTnVrVgfWr1/vVLdmHVTRyj6NrX9SkmeoMWvnOnXqxB577MErr7xS7VDMrMJKacbvDTwj6THg7VxhRLiHj1k7s2TJEnbbbTeGDBnClltumSv+SDVjMrPyK6WyP7fsUZhZRZx99tmblN12221NDqU1s/atlHH2D0j6MDAoIu6RtAXg/NNm7dABBxzAyy+/zAsvvMBBBx3EO++8A/BOteMys/IqJRHON8mSy2wL7EyWNOPXNDIxjpnVriuuuIKJEyfyxhtvsGDBAl577TVwM75Z3StlnP1YsqlvVwJExAvA9kW3MLOa9Ktf/YqHH36Ynj17AjBo0CDwEFyzuldKZb86ItbknkjqQiMpZs2stnXr1o2uXbu+/3zt2rVVjMbMKqWUyv4BSacD3SV9HrgRuK28YZlZORxwwAH8+Mc/5t133+Xuu+/myCOPBGiT1HdmVrtKqexPA5YD84BvAXcCZ5YzKDMrjwkTJtCrVy8+8YlP8Jvf/IZDDz0U4LVqx2Vm5VVKb/z1kq4CZpI13z8XEU0240uaBHwRWBYRu6eyc4Bvkn15ADg9Iu5Mr40HjgfWASdGxJ9S+T5sSG97J3BSKcc3s0116tSJ0aNH88lPfhJJ7LLLLowZM6baYXVI+VPrLppwWBUjsY6glN74h5H1vl9AlrJ2oKRvRURTOeWnAL8Erm5Q/rOI+GmDY+wKHAXsBuwI3CPpoymf/eVkowEeJavsh+N89mYtcscdd/Dtb3+bnXfemYhg4cKFAD2rHZeZlVcpvXAvAj4bES8CSNoZuIMmKtyIeFDSgBLjGAHcEBGrgYWSXgSGSFoE9IyIR9KxrwZGNnVsMyts3Lhx3HfffXzkI9louwULFvCRj3ykX5XDMrMyK+We/bJcRZ+8BCxrxTG/K+kpSZMkbZPK+gCv5q2zOJX1ScsNy82sBbbffvv3K3qAnXbaCcBd8s3qXKNX9pJGpcVnJN0JTCW7Z38k8HgLj3c5cF7az3lkrQbfILs90FAUKW8s5jFkTf707+/cPWY506ZNA2C33Xbj0EMP5Stf+QqSuPHGGyEv54WZ1adizfhfylteChyQlpcD22y6etMiYmluWdIVwO3p6WIgvymxL/B6Ku9boLyx/U8EJgIMHjzYnfjMkttu2zBadocdduCBBx4AoFevXuBJdczqXqMneUR8va0PJql3RCxJT78MPJ2WpwPXSbqYrIPeIOCxiFgnaZWkoWSjAY4FLm3ruMzq3eTJkxt9bcqUKYtau39JnYFZwGsR8UVJ2wK/BwYAi4CvRMQ/0roFR96YWfmU0ht/IPA9spP2/fWbSnEr6XpgGLCdpMXA2cAwSXuSNcUvIhu3T0Q8I2kq8Bey+4djU098gBPYMPTuLtw5z6zFFi5cyKWXXsqiRYvyZ89ri7nxTwLms6Fn/2nAvRExQdJp6fmpTYy8MbMyKaX57lbgSrJZ89aXuuOIOLpA8ZVF1r8AuKBA+Sxg91KPa2aNGzlyJMcffzxf+tKX6NQp65/b2hS3kvoCh5Gdv6ek4hFkX/YBrgLuB06lkZE3wCOticHMiiulsv9nRPyi7JHUmPwJL8CTXlh92HzzzTnxxBMbFr/Vyt3+HPgh0COvbIfcLbuIWCIplzyrD9mcGTkeYWNWAaVU9pdIOhuYAazOFUbEnLJFZWZlcdJJJ3Huuedy8MEH061bt1zxFi3dn6TcLJmzJQ0rZZMCZZt0pvXIGrO2VUpl/wngGOBzbGjGj/TczNqRefPmcc011/DnP//5/WZ8Nh7x0lz7AYdLOhTYHOgp6XfA0lyHXEm92TA3R2MjbzbikTVmbauUyv7LwE75aW7NrH265ZZbeOmllzZKcyvp+ZbuLyLGA+PTfoYB/xURX5P0v8BoYEL6+Ye0ScGRNy09fnvS8NagWSWVMoPek8DW5Q7EzMpvjz324M0336zEoSYAn5f0AvD59JyIeIZsgq6/AH9k45E3ZlYmpVzZ7wA8K+lxNr5nX3TonZnVnqVLl/Kxj32MfffdN/+efVsMvSMi7ifrdU9E/B04sJH1Co68MbPyKaWyP7vsUZhZRZx77rmblLV26J2Z1b5S8tk/UIlAzKz8DjjggELFrR16Z2Y1rpQZ9FaxYWhMV2Az4O2IcA5ss3amR48eSNnotzVr1vDee+8B7FXVoMys7JrsoBcRPSKiZ3psDvwb8Mvyh2ZmbW3VqlWsXLmSlStX8s9//pObb74ZWpey2szagVJ6428kIm7FY+zN6sLIkSNh45nvzKwOldKMPyrvaSdgMEVyyptZ7crltQdYv349s2bNqmI0ZlYppfTGz89rv5YsW92IskRjZmWVn9e+S5cuDBgwAODFasVjhTk3h7W1UnrjtyivvaRJQG7e7N1TWbNzXEvahw0pbu8ETooItyyYtUChvPZnnnnm2gKrmlkdabSyl/TfRbaLiDiviX1PIevId3VeWUtyXF9OlhDjUbLKfjjOaW/WLD/60Y+Kvdy7UnGYWXUU66D3doEHZFffpza144h4EHijQfEIstzWpJ8j88pviIjVEbGQrFlxSEqg0TMiHklX81fnbWNmJdpyyy03eQBceeWVAB+qanBmVnaNXtlHxEW5ZUk9gJOArwM3ABc1tl0Tmpvj+r203LC8IKfFNCts3Lhx7y+vWrWKSy65hMmTJ3PUUUfxk5/8ZF4VQzOzCig69E7StpLOB54i+2Kwd0ScGhFtPS63sRzXJeW+fv+FiIkRMTgiBvfq1avNgjOrB2+88QZnnnkm//Iv/8LatWuZM2cOF154IWQdb82sjhW7Z/+/wCiynNKfiIi2mFKzuTmuF7Nxru2Cua/NrLgf/OAHTJs2jTFjxjBv3jy22mqraodkZhVUrDf+OLIsd2cCZ+Sm2CS72o4WTpc7nWbkuI6IdZJWSRoKzASOBS5twXHNOrSLLrqIbt26cf7553PBBRsSzqWBLZ4ut8qc697Krdg9+2bPrpdP0vXAMGA7SYvJsudNAKZKOh54BTgyHesZSbkc12vZOMf1CWwYencX7olv1mzr169v9DVJT1QwFDOrglIm1WmRiDi6kZealeM6ImYBu7dhaGZmZh1Kq67ezczMrPa5sjczM6tzruzNzMzqnCt7MzOzOle2Dnr1xlmozMysvXJlb2YtJqkfWc6KDwHrgYkRcUlLMlxaaXzhYS3hZnwza421wLiI+DgwFBibsljmMlwOAu5Nz2mQ4XI4cJmkzlWJ3KwDcWVvZi0WEUsiYk5aXgXMJ0tW1awMl5WN2qzjcWVvZm1C0gCyqXdn0iDDJZCf4fLVvM0KZrKUNEbSLEmzli9fXs6wzToEV/Zm1mqStgJuBk6OiJXFVi1QtkkmS2ewNGtb7qBnZq0iaTOyiv7aiJiWipub4dKKcKIcay1f2ZtZiylLh3klMD8iLs57KZfhEjbNcHmUpG6SBpIyXFYqXrOOylf2ZtYa+wHHAPMkzU1lp9OyDJdmViZVqewlLQJWkY2zXRsRgz0u16z9iYiHKHwfHpqZ4bItudnbbGPVbMb/bETsGRGD03OPyzUzMyuDWmrGHwEMS8tXAfcDp5I3LhdYKCk3LveRKsRoZlbTPMOeFVKtK/sAZkiaLWlMKmvVuFzw2FwzM7NCqnVlv19EvC5pe+BuSc8WWbekcbmQjc0FJgIMHjy44DpmZmYdTVWu7CPi9fRzGXALWbP80jQeF4/LNTMzazsVr+wlbSmpR24ZOBh4Go/LNTMzK4tqNOPvANySzcVBF+C6iPijpMfxuFwzM7M2V/HKPiJeAvYoUP53qjgut7nye7y6t6uZmdWyWhp6Z2ZmzdScCYQ8LK/j8tz4ZmZmdc5X9mZmdcxTBxv4yt7MzKzuubI3MzOrc67szczM6pzv2bcB93A1M7Na5srezKyDKtZ5zxct9cXN+GZmZnXOlb2ZmVmdczN+GfgevpnVG3+utW++sjczM6tz7ebKXtJw4BKgM/DbiJhQ5aRADHQAAAmwSURBVJBK5qQ5Zhu053PZCvNVf+1rF5W9pM7Ar4DPA4uBxyVNj4i/VDey5vNJYR1Zuc5lTwnb9pp6T/2ety/torIHhgAvpvS4SLoBGEGW475dc+VvHUzdnsvWOLduVl97qez7AK/mPV8MfLJKsZRVa74tN+ck8slnVdJhzuWOrNjnWLVaBDr651x7qexVoCw2WUkaA4xJT9+S9FyRfW4H/K0NYiu3kuPUhS07QEu3a6C9vJ/QfmKtVJwfrsAxcspxLreVWvy/qLWYai0eKDGmNvqcK1W13qdGz+X2UtkvBvrlPe8LvN5wpYiYCEwsZYeSZkXE4LYJr3wcZ9trL7G2lzibqc3P5bZSi+93rcVUa/GAYypVexl69zgwSNJASV2Bo4DpVY7JzJrP57JZFbSLK/uIWCvpu8CfyIbrTIqIZ6oclpk1k89ls+poF5U9QETcCdzZhrusaBNhKzjOttdeYm0vcTZLGc7ltlKL73etxVRr8YBjKokiNukbY2ZmZnWkvdyzNzMzsxbqcJW9pOGSnpP0oqTTqnD8fpLukzRf0jOSTkrl20q6W9IL6ec2eduMT/E+J+kLeeX7SJqXXvuFpELDmlobb2dJT0i6vcbj3FrSTZKeTe/tp2oxVknfT3/3pyVdL2nzWoyznhU5B8+R9JqkuelxaIXjWpT+pnMlzUpljf5vVCCeXfLei7mSVko6udLvk6RJkpZJejqvrNnnTAVi+t/0+fOUpFskbZ3KB0h6N+/9+nU5YmpSRHSYB1mHoAXATkBX4Elg1wrH0BvYOy33AJ4HdgV+ApyWyk8DLkzLu6Y4uwEDU/yd02uPAZ8iG7t8F3BIGeI9BbgOuD09r9U4rwL+My13BbautVjJJpRZCHRPz6cCx9VanPX+KHIOngP8VxXjWgRs16Cs4P9GFWLrDPyVbBx3Rd8n4DPA3sDTTb0vxc6ZCsR0MNAlLV+YF9OA/PWq9ehoV/bvT9UZEWuA3FSdFRMRSyJiTlpeBcwnqwRGkFVYpJ8j0/II4IaIWB0RC4EXgSGSegM9I+KRyP6jrs7bpk1I6gscBvw2r7gW4+xJdvJdCRARayLizVqMlaxTbHdJXYAtyMaY12KcdavIOViLGvvfqLQDgQUR8XKlDxwRDwJvNChu1jlTiZgiYkZErE1PHyWbQ6JmdLTKvtBUnVU7ySUNAPYCZgI7RMQSyD6MgO3Tao3F3CctNyxvSz8HfgiszyurxTh3ApYDk9Mth99K2rLWYo2I14CfAq8AS4AVETGj1uLsSBqcgwDfTc2wkyrZZJ4EMEPSbGUzCELj/xuVdhRwfd7zar5P0PxzptK+QdbiljMwfTY9IOnTVYinw1X2JU3VWQmStgJuBk6OiJXFVi1QFkXK24SkLwLLImJ2qZs0Ek8l3vMuZE1ql0fEXsDbZE17janWe7oN2ZXHQGBHYEtJXyu2SSPx1Mz/cXtW4By8HNgZ2JPsy9hFFQ5pv4jYGzgEGCvpMxU+fkHKJj86HLgxFVX7fSqm6ueGpDOAtcC1qWgJ0D99Np0CXJdaIyuqo1X2JU3VWW6SNiP7kLk2Iqal4qWpeZb0c1kqbyzmxWzcTNTWv8t+wOGSFpHd7vicpN/VYJy5Yy+OiNzV2U1klX+txXoQsDAilkfEe8A04F9rMM66V+gcjIilEbEuItYDV1CG5t9iIuL19HMZcEs6fmP/G5V0CDAnIpam+Kr6PiXNPWcqQtJo4IvAV9MtNtIthb+n5dlk/Qg+WqmYcjpaZV/1qTpTr+krgfkRcXHeS9OB0Wl5NPCHvPKjJHWTNBAYBDyWmq5WSRqa9nls3jatFhHjI6JvRAwge5/+HBFfq7U4U6x/BV6VtEsqOpAsZWqtxfoKMFTSFmn/B5LdL661OOtaY+dgrvJIvgw83XDbMsa0paQeuWWyzl5P0/j/RiUdTV4TfjXfpzzNOmcqEZCk4cCpwOER8U5eeS9JndPyTimmlyoR00aq3UOw0g/gULLetwuAM6pw/P3JmpWeAuamx6HAB4F7gRfSz23ztjkjxfsceb2ugcFkJ9oC4JekSZLKEPMwNvTGr8k4yZoUZ6X39VZgm1qMFTgXeDYd4xqyXsM1F2c9P4qcg9cA81L5dKB3BWPaiawX+ZPAM7nPpmL/GxWKawvg78AH8soq+j6RfdFYArxHduV+fEvOmQrE9CJZf4Hc/9Sv07r/lv6mTwJzgC9V8m+Ye3gGPTMzszrX0ZrxzczMOhxX9mZmZnXOlb2ZmVmdc2VvZmZW51zZm5mZ1TlX9nVO0ltl3v9xknbMe75I0nat2N/1aRrO7+eVnZGXMWpd3vKJLdj/KEkfa2l8ZtXic3mT/ftcboYu1Q7A2r3jyMZ7t3qWKkkfAv41Ij6cXx4RFwAXpHXeiog9W3GYUWRz/T/bin2Y1aPj8Llct3xl3wGlGZ1ulvR4euyXys9JiS3ul/RS/rdtSWcpy9V8d/rG/l+SjiCb3OXa9O28e1r9e5LmKMvNvck3b2U53Cen15+Q9Nn00gxg+7SvkpJFSNpB0jRJsyQ9JmloKr9M0ulp+TBl+cs/TTZ5ys/SMQa06A00qxE+l30ul6waM/n4UbkH8FaBsuuA/dNyf7JpQyHLU/1/ZLO6bUc2c9ZmZB8Cc4HuZPm/XyDlswbuBwbn7XsR8L20/B3gtwWOPw6YnJY/RjaN7OaUkPe54e8D/B4Ympbf3x7YkmzK3GFkMyYOTOW/A0ZW++/ihx/Nffhc9rncmoeb8Tumg4BdpfcTRPXMzcsN3BERq4HVkpYBO5BNL/qHiHgXQNJtTew/l9xnNllTW0P7A5cCRMSzkl4mSwxRLPtfsd9ll7zfZRtJ3SPibUnfBv5M9oG1sAX7Nqt1PpetJK7sO6ZOwKdyJ3xOOslW5xWtI/sfKZQ2spjcPnLbN9Tc/RUjYEhErCnw2ifIrmh2LPCaWT3wuWwl8T37jmkG8N3cE0lNdZJ5CPhSuj+3FXBY3muryJoDm+NB4Kvp2B8la358rpn7yLkHGJt7kvtdlGWXOpEsQc4ISYNbEa9ZrfK5bCVxZV//tpC0OO9xCtmJM1jZsJi/AN8utoOIeJwsu9WTZM16s4AV6eUpwK8bdOppymVAZ0nzyO7THZeaG1tiLLBf3u/yTWWXNZOA70eWDvY/gSsldSPLVnW6O/VYO+Rz2edyiznrnZVE0lYR8ZakLci+zY+JiDnVjsvMmsfncsfke/ZWqomSdiXraXuVPxzM2i2fyx2Qr+zNzMzqnO/Zm5mZ1TlX9mZmZnXOlb2ZmVmdc2VvZmZW51zZm5mZ1TlX9mZmZnXu/wNA2j5vdrjuXgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"cleaned_text 의 최대 길이 : {max([len(txt) for txt in cleaned_text])}\")\n",
    "print(f\"cleaned_text 의 최소 길이 : {min([len(txt) for txt in cleaned_text])}\")\n",
    "print(f\"cleaned_text 의 평균 길이 : {np.mean([len(txt) for txt in cleaned_text]):.2f}\")\n",
    "print(f\"cleaned_summary 의 최대 길이 : {max([len(txt) for txt in cleaned_summary])}\")\n",
    "print(f\"cleaned_summary 의 최소 길이 : {min([len(txt) for txt in cleaned_summary])}\")\n",
    "print(f\"cleaned_summary 의 평균 길이 : {np.mean([len(txt) for txt in cleaned_summary]):.2f}\")\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 3))\n",
    "ax1.hist([len(txt) for txt in cleaned_text], bins=50)\n",
    "ax1.set_xlabel(\"Length of Text\")\n",
    "ax1.set_ylabel(\"Number of Texts\")\n",
    "ax1.set_title(\"Text\")\n",
    "\n",
    "ax2.hist([len(txt) for txt in cleaned_summary], bins=50)\n",
    "ax2.set_xlabel(\"Length of Text\")\n",
    "ax2.set_ylabel(\"Number of Texts\")\n",
    "ax2.set_title(\"Summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y7btzZwWzHQt"
   },
   "outputs": [],
   "source": [
    "# Calculate max_length of the target tensors\n",
    "max_length_text = 100\n",
    "max_length_summary = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dm9b6PuizHQy"
   },
   "outputs": [],
   "source": [
    "def tokenize(data, max_length):\n",
    "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')  #filters='' 않으면 <>  filtering\n",
    "    \n",
    "    lang_tokenizer.fit_on_texts(data)\n",
    "\n",
    "    tensor = lang_tokenizer.texts_to_sequences(data)\n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, maxlen=max_length, padding='post')\n",
    "\n",
    "    return tensor, lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qsvcDoUPzHQ0"
   },
   "outputs": [],
   "source": [
    "text_tensor, text_tokenizer = tokenize(cleaned_text, max_length_text)\n",
    "summary_tensor, summary_tokenizer = tokenize(cleaned_summary, max_length_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "gaRNPOgzzHQ8",
    "outputId": "9fed3109-7ad9-494b-8724-c35467898530"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7610 7610\n",
      "1903 1903\n"
     ]
    }
   ],
   "source": [
    "# training, validation set 을 80-20 으로 분할\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val \\\n",
    "                                        = train_test_split(text_tensor, summary_tensor, test_size=0.2)\n",
    "\n",
    "print(len(input_tensor_train), len(target_tensor_train))\n",
    "print(len(input_tensor_val), len(target_tensor_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lOVcWKuazHRB"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 10000   \n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = 500    #len(input_tensor_train)//BATCH_SIZE    \n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(text_tokenizer.word_index) + 1       \n",
    "vocab_tar_size = len(summary_tokenizer.word_index) + 1      \n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "iiyLKiShzHRE",
    "outputId": "c6d79bf2-e86d-486e-9bf1-c19e464bfb36"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 100]), TensorShape([64, 20]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qj9ImDPizHRH"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                        return_sequences=True,\n",
    "                                        return_state=True,\n",
    "                                        recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state = hidden)\n",
    "        return output, state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "vKkZLIHPzHRJ",
    "outputId": "55ef1d21-475a-45ac-88cb-3e45a2b5e627"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, max input sequence length, units) (64, 100, 1024)\n",
      "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "# sample input\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "print ('Encoder output shape: (batch size, max input sequence length, units) {}'\n",
    "                       .format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "btYxywgazHRM"
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "\n",
    "        # score shape == (batch_size, max_length, 1) -> (64, 16, 1)  \n",
    "        # we get 1 at the last axis because we are applying score to self.V\n",
    "        hidden_with_time_axis = tf.expand_dims(query, 1)\n",
    "        score = self.V(tf.nn.tanh(self.W1(values) + self.W2(hidden_with_time_axis)))\n",
    "\n",
    "        # attention_weights shape == (batch_size, input_lang_max_length, 1) -> (64, 16, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        # context_vector(어텐션 값) shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "0qKSbH9bzHRQ",
    "outputId": "51049df3-0cd4-4649-d28d-13b8719f59f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, hidden_units) (64, 1024)\n",
      "Attention weights shape: (batch_size, input_lang_max_sequence_length, 1) (64, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = BahdanauAttention(10)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, hidden_units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, input_lang_max_sequence_length, 1) {}\"\n",
    "                  .format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NX_CIUmPzHRT"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                        return_sequences=True,\n",
    "                                        return_state=True,\n",
    "                                        recurrent_initializer='glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)     # vocab_size - target_lang vocab_size (4935)\n",
    "\n",
    "        # used for attention\n",
    "        self.attention = BahdanauAttention(self.dec_units)        \n",
    "\n",
    "    def call(self, x, hidden, enc_output):\n",
    "        # context_vector (batch_size, hidden_size) -> (64, 1024)\n",
    "        # attention_weights (64, 16, 1)\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "\n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        # (64, 1, 256)\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        # attention 값 (context vector) 과 timestep t 의 output 을 연결\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "        # passing the concatenated vector to the GRU\n",
    "        output, state = self.gru(x)\n",
    "\n",
    "        # output shape == (batch_size * 1, hidden_size)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "        # output shape == (batch_size, vocab) -> (64, 4935)\n",
    "        x = self.fc(output)\n",
    "\n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "IXapUuIezHRV",
    "outputId": "ca13827d-75e0-4a04-af76-15b43f822971"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, target_lang_vocab size) (64, 4746)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
    "                                      sample_hidden, sample_output)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, target_lang_vocab size) {}'\n",
    "                       .format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xAij2YXEzHRY"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "                    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):     \n",
    "\n",
    "    # batch 64 개 record 중 timestep t 에 0 padding 이 아닌 \n",
    "    # 실제 단어가 존재하는 record 만 True 로 만듦\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))    \n",
    "\n",
    "    # [word_index] 에 대한 확률분포 array - (64, ), dtype=float32 \n",
    "    loss_ = loss_object(real, pred)    \n",
    "\n",
    "    # mask dtype 을 float32 로 type cast\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)   \n",
    "\n",
    "    loss_ *= mask             # 실제 단어가 존재하는 위치 외에는 모두 0 으로 만든다\n",
    "\n",
    "    return tf.reduce_mean(loss_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HLk-bzP_zHRa"
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f90V6pZwzHRd"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "        # decoder hidden state 의 초기값은  encoder  last hidden state\n",
    "        dec_hidden = enc_hidden   \n",
    "\n",
    "        # dec_input shape (batch_size, 1) \n",
    "        dec_input = tf.expand_dims([summary_tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "        # Teacher forcing - feeding the target as the next input\n",
    "        for t in range(1, targ.shape[1]):    \n",
    "            # passing enc_output to the decoder\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "\n",
    "            loss += loss_function(targ[:, t], predictions)  \n",
    "\n",
    "            # using teacher forcing - predictions 가 아닌 true value 를 next step 의 dec_input 으로 제공\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 857
    },
    "colab_type": "code",
    "id": "0HYe1UIvzHRf",
    "outputId": "b2f96a1a-5bbf-4018-d263-381383eaab1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 0.7082\n",
      "Epoch 1 평균 Loss 0.0146\n",
      "Time taken for 1 epoch 13.017994403839111 sec\n",
      "\n",
      "1588382603.974459\n",
      "1588382590.9564645\n",
      "13.017994403839111\n",
      "Epoch 2 Batch 0 Loss 0.7742\n",
      "Epoch 2 평균 Loss 0.0155\n",
      "Time taken for 1 epoch 13.828005313873291 sec\n",
      "\n",
      "1588382617.8024642\n",
      "1588382603.974459\n",
      "26.845999717712402\n",
      "Total elapse time\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "elapse_time = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    \n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                        batch,\n",
    "                                                        batch_loss.numpy()))\n",
    "    # saving (checkpoint) the model every 2 epochs\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print('Epoch {} 평균 Loss {:.4f}'.format(epoch + 1, total_loss / steps_per_epoch))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n",
    "    elapse_time += time.time() - start\n",
    "    \n",
    "print('Total elapse time: {}'.format(elapse_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "zehZpUyBzHRi",
    "outputId": "4aac297e-97fb-4840-96aa-259d0e12dc5b"
   },
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "\n",
    "    sentence = preprocess_sentence(sentence)[0]\n",
    "\n",
    "    inputs = [text_tokenizer.word_index.get(i, 0) for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                            maxlen=max_length_text,\n",
    "                                                            padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "    result = ''\n",
    "\n",
    "    hidden= [tf.zeros((1, units))]   # units : 1024\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([summary_tokenizer.word_index['<start>']], 0)\n",
    "\n",
    "    # inference step\n",
    "    for t in range(max_length_summary):      \n",
    "        predictions, dec_hidden, attention_weights  \\\n",
    "                = decoder(dec_input, dec_hidden, enc_out)\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "        result += summary_tokenizer.index_word[predicted_id] + ' '\n",
    "\n",
    "        if summary_tokenizer.index_word[predicted_id] == '<end>':\n",
    "             return result, sentence\n",
    "\n",
    "        # the predicted ID is fed back into the model - no teacher-forcing\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uNU7JMFaBJN2"
   },
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "    print(sentence)\n",
    "    result, sentence = evaluate(sentence)\n",
    "\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "GSV5X775BV-v",
    "outputId": "a7f58afe-4346-4927-f1f6-9d593366ecf4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x206541d6a88>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333
    },
    "colab_type": "code",
    "id": "XCDz-arqBatx",
    "outputId": "5c99b52b-9194-4697-b57d-88b7f070c2f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i have bought several of the vitality canned dog food products and have found them all to be of good quality the product looks more like a stew than a processed meat and it smells better my labrador is finicky and she appreciates this product better than  most']\n",
      "Input: <start> i have bought several of the vitality canned dog food products and have found them all to be of good quality the product looks more like a stew than a processed meat and it smells better my labrador is finicky and she appreciates this product better than  most <end>\n",
      "Predicted translation: great product <end> \n"
     ]
    }
   ],
   "source": [
    "translate(['i have bought several of the vitality canned dog food products and have found them all to be of good quality the product looks more like a stew than a processed meat and it smells better my labrador is finicky and she appreciates this product better than  most'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b0o71uKXEIQ4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "095_text_summation_with_attention.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
